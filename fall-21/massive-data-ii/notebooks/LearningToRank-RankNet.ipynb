{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidad 4: Sistemas de Recomendación - Learning To Rank - RankNet\n",
    "\n",
    "- [Github de clase](https://github.com/blancavazquez/CursoDatosMasivosII/blob/master/notebooks/4e_learningToRank.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Dense, Input, Subtract\n",
    "from keras.models import Model\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación y Transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3)\n",
      "(50, 3)\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 3\n",
    "\n",
    "X1 = 2 * np.random.uniform(size=(50, INPUT_DIM))\n",
    "X2 = np.random.uniform(size=(50, INPUT_DIM))\n",
    "Y = [random.randint(0,1) for _ in range(50)]\n",
    "\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "mms.fit(np.concatenate((X1,X2), axis=0))\n",
    "\n",
    "X1 = mms.transform(X1)\n",
    "X2 = mms.transform(X2)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538880</td>\n",
       "      <td>0.946651</td>\n",
       "      <td>0.618972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.483949</td>\n",
       "      <td>0.988301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>0.119546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808717</td>\n",
       "      <td>0.297588</td>\n",
       "      <td>0.487159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.435009</td>\n",
       "      <td>0.905335</td>\n",
       "      <td>0.517752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature1  Feature2  Feature3\n",
       "0  0.538880  0.946651  0.618972\n",
       "1  0.809106  0.483949  0.988301\n",
       "2  0.719178  0.307825  0.119546\n",
       "3  0.808717  0.297588  0.487159\n",
       "4  0.435009  0.905335  0.517752"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = pd.DataFrame(X1, columns=[\"Feature1\", \"Feature2\", \"Feature3\"])\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RankNet_model(input_shape):\n",
    "    \"\"\"\n",
    "    Construcción de la red neuronal siamesa\n",
    "    \"\"\"\n",
    "    h1 = Dense(4, activation=\"relu\", name=\"Relu_layer1\")\n",
    "    h2 = Dense(2, activation=\"relu\", name=\"Relu_layer2\")\n",
    "    h3 = Dense(1, activation=\"linear\", name=\"Identity_layer\")\n",
    "    \n",
    "    input1 = Input(shape=(input_shape,), name=\"Input_layer1\")\n",
    "    x1 = h1(input1)\n",
    "    x1 = h2(x1)\n",
    "    x1 = h3(x1)\n",
    "    \n",
    "    input2 = Input(shape=(input_shape,), name=\"Input_layer2\")\n",
    "    x2 = h1(input2)\n",
    "    x2 = h2(x2)\n",
    "    x2 = h3(x2)\n",
    "    \n",
    "    # Capa de comparación\n",
    "    subtracted = Subtract(name=\"Subtract_layer\")([x1, x2])\n",
    "    \n",
    "    # Función de activación\n",
    "    out = Activation('sigmoid', name=\"Activation_layer\")(subtracted)\n",
    "    \n",
    "    # Modelo\n",
    "    model = Model(inputs=[input1, input2], outputs=out, name=\"RankNet_model\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RankNet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_layer1 (InputLayer)       [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_layer2 (InputLayer)       [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Relu_layer1 (Dense)             (None, 4)            16          Input_layer1[0][0]               \n",
      "                                                                 Input_layer2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Relu_layer2 (Dense)             (None, 2)            10          Relu_layer1[0][0]                \n",
      "                                                                 Relu_layer1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Identity_layer (Dense)          (None, 1)            3           Relu_layer2[0][0]                \n",
      "                                                                 Relu_layer2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Subtract_layer (Subtract)       (None, 1)            0           Identity_layer[0][0]             \n",
      "                                                                 Identity_layer[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Activation_layer (Activation)   (None, 1)            0           Subtract_layer[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 29\n",
      "Trainable params: 29\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = RankNet_model(INPUT_DIM)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 772us/step - loss: 0.6271\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 911us/step - loss: 0.6270\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 860us/step - loss: 0.6267\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6264\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6264\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6263\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6263\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6261\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6260\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6260\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6260\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6262\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6260\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6259\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6259\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6259\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6259\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6258\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6259\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6257\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6257\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6258\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6257\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6256\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6256\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6255\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6254\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6253\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6253\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6253\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6253\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6254\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6252\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6251\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6251\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6250\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6251\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6251\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6249\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6248\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6249\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6250\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6249\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6249\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6248\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6247\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6246\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6246\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6246\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6247\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6246\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6245\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6249\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6245\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6245\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6246\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6245\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6242\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6243\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6242\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6241\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6240\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6240\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6240\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6240\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6240\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6239\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6239\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6238\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6239\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6239\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6238\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6236\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6239\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6239\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6239\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6236\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6234\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6239\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6236\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6233\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6237\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6235\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6236\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6232\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6234\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6231\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6232\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6230\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6231\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6231\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6231\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6230\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6232\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6229\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6229\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6230\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6227\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6228\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcaf83de970>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.fit([X1, X2], Y, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salida del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ranknet_output = K.function([model.layers[0].input], [model.layers[-3].get_output_at(0)])\n",
    "Ranknet_output = get_ranknet_output([X1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.277203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.347710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.463326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.481433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-3.769359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.066299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.694526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.032006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.101342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.012385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-2.869967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-1.140975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.145722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "0   0.000000\n",
       "1   0.000000\n",
       "2  -0.277203\n",
       "3   0.000000\n",
       "4   0.000000\n",
       "5   0.000000\n",
       "6   0.000000\n",
       "7   0.000000\n",
       "8   0.000000\n",
       "9   0.000000\n",
       "10  0.000000\n",
       "11  0.000000\n",
       "12  0.000000\n",
       "13  0.000000\n",
       "14 -1.347710\n",
       "15  0.000000\n",
       "16 -0.463326\n",
       "17  0.000000\n",
       "18 -0.481433\n",
       "19  0.000000\n",
       "20  0.000000\n",
       "21  0.000000\n",
       "22  0.000000\n",
       "23 -3.769359\n",
       "24 -0.066299\n",
       "25 -0.694526\n",
       "26  0.000000\n",
       "27 -0.032006\n",
       "28 -0.101342\n",
       "29  0.000000\n",
       "30  0.000000\n",
       "31  0.000000\n",
       "32  0.000000\n",
       "33  0.000000\n",
       "34  0.000000\n",
       "35  0.000000\n",
       "36  0.000000\n",
       "37  0.000000\n",
       "38  0.000000\n",
       "39  0.000000\n",
       "40  0.000000\n",
       "41 -0.012385\n",
       "42 -2.869967\n",
       "43  0.000000\n",
       "44 -1.140975\n",
       "45 -1.145722\n",
       "46  0.000000\n",
       "47  0.000000\n",
       "48  0.000000\n",
       "49  0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = pd.DataFrame(Ranknet_output, columns=[\"score\"])\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
