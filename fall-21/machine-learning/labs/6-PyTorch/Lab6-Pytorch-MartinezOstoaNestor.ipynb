{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 6: PyTorch\n",
    "\n",
    "- Martínez Ostoa Néstor I.\n",
    "- Aprendizaje de Máquina\n",
    "- LCD - IIMAS - UNAM \n",
    "\n",
    "---\n",
    "Utilizar la libreta disponible en https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "\n",
    "1) Cambiar el modelo para utilizar alguno de https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "2) Ejecutar el código correspondiente cambiando el número de épocas y factor de aprendizaje\n",
    "\n",
    "3) Reportar el valor de error de entrenamiento encontrado al final del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de datos\n",
    "\n",
    "Para este laboratorio trabajeremos con el dataset **[FashionMINST](https://github.com/zalandoresearch/fashion-mnist)**. \n",
    "\n",
    "Cada muestra de datos contiene lo siguiente:\n",
    "\n",
    "- Imagen de $28\\times 28$ pixeles asociada a una de las 10 clases disponibles\n",
    "- Clases:\n",
    "\n",
    "|Etiqueta|Descripción|\n",
    "|--------|-----------|\n",
    "|0|T-shirt/top|\n",
    "|1|Trouser|\n",
    "|2|Pullover|\n",
    "|3|Dress|\n",
    "|4|Coat|\n",
    "|5|Sandal|\n",
    "|6|Shirt|\n",
    "|7|Sneaker|\n",
    "|8|Bag|\n",
    "|9|Ankle boot|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_rgb = T.Lambda(lambda image: image.convert('RGB'))\n",
    "resize = T.Resize((224, 224))\n",
    "my_transform = T.Compose([resize, to_rgb, T.ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=my_transform,\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=my_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, creamos un *wrapper** iterable sobre el datset obtenido previamente. Para esto, pasamos el ```Dataset``` como argumento al ```DataLoader```. Este paso ofrece lo siguiente:\n",
    "\n",
    "- Batch automático\n",
    "- *Shuffling*\n",
    "- Carga de datos multiproceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 3, 224, 224])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "\n",
    "- Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de parámetros del modelo\n",
    "\n",
    "Para entrenar un modelo, necesitamos definar una función de pérdida ```losss``` y un optimizador ```optimizer```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, verbose=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de **entrenamiento** se realiza sobre varias iteraciones (llamadas *epochs*). Durante cada *epoch*, el modelo aprende los parámetros necesarios para realizar mejores predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.295326  [    0/60000]\n",
      "loss: 2.298383  [ 6400/60000]\n",
      "loss: 2.291610  [12800/60000]\n",
      "loss: 2.290938  [19200/60000]\n",
      "loss: 2.283046  [25600/60000]\n",
      "loss: 2.289245  [32000/60000]\n",
      "loss: 2.270028  [38400/60000]\n",
      "loss: 2.268670  [44800/60000]\n",
      "loss: 2.248740  [51200/60000]\n",
      "loss: 2.232937  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 16.2%, Avg loss: 2.213443 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.220263  [    0/60000]\n",
      "loss: 2.228171  [ 6400/60000]\n",
      "loss: 2.140955  [12800/60000]\n",
      "loss: 2.072320  [19200/60000]\n",
      "loss: 1.531070  [25600/60000]\n",
      "loss: 1.382225  [32000/60000]\n",
      "loss: 1.189878  [38400/60000]\n",
      "loss: 1.295505  [44800/60000]\n",
      "loss: 1.129514  [51200/60000]\n",
      "loss: 0.988413  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.037142 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.133973  [    0/60000]\n",
      "loss: 1.165417  [ 6400/60000]\n",
      "loss: 0.845403  [12800/60000]\n",
      "loss: 1.116840  [19200/60000]\n",
      "loss: 1.030196  [25600/60000]\n",
      "loss: 1.012407  [32000/60000]\n",
      "loss: 0.883153  [38400/60000]\n",
      "loss: 0.973718  [44800/60000]\n",
      "loss: 0.940019  [51200/60000]\n",
      "loss: 0.853508  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.872436 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.774221  [    0/60000]\n",
      "loss: 0.763521  [ 6400/60000]\n",
      "loss: 0.640123  [12800/60000]\n",
      "loss: 0.883309  [19200/60000]\n",
      "loss: 0.876361  [25600/60000]\n",
      "loss: 0.844765  [32000/60000]\n",
      "loss: 0.835636  [38400/60000]\n",
      "loss: 0.703513  [44800/60000]\n",
      "loss: 0.750751  [51200/60000]\n",
      "loss: 0.842746  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.754051 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.650020  [    0/60000]\n",
      "loss: 0.796165  [ 6400/60000]\n",
      "loss: 0.538905  [12800/60000]\n",
      "loss: 0.788004  [19200/60000]\n",
      "loss: 0.791078  [25600/60000]\n",
      "loss: 0.833749  [32000/60000]\n",
      "loss: 0.700253  [38400/60000]\n",
      "loss: 0.752450  [44800/60000]\n",
      "loss: 0.773880  [51200/60000]\n",
      "loss: 0.623957  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.697982 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almacenamiento de modelos entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados finales**:\n",
    "\n",
    "- Modelo: Alexnet\n",
    "- Epochs: 5\n",
    "- Learning rate: 1e-3\n",
    "- Accuracy: 74,2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
