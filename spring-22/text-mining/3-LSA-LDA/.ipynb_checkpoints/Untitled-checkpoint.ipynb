{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rolled-tuner",
   "metadata": {},
   "source": [
    "# Tarea 3\n",
    "\n",
    "- Martínez Ostoa Néstor I. \n",
    "- Minería de Textos\n",
    "- LCD - IIMAS - UNAM\n",
    "\n",
    "---\n",
    "\n",
    "*Descargar el archivo wiki-sub.jsonl y realizar las siguientes actividades. Este archivo tiene 100k documentos, cada uno de ellos corresponde a la introducción de un artículo de Wikipedia.*\n",
    "\n",
    "*Descargar el archivo query-sub.jsonl. Este archivo contiene 50 consultas que serán utilizadas para evaluar las propuestas de RI. Cada consulta tiene los identificadores de los documentos que fueron evaluados como relevantes.*\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "covered-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loved-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.read_json('docs.json', lines=True)\n",
    "queries_df = pd.read_json('query.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modern-european",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: (100000, 2)\n",
      "Queries: (50, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Documents: {docs_df.shape}\\nQueries: {queries_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "orange-valuable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HazMat_-LRB-film-RRB-</td>\n",
       "      <td>HazMat is a 2013 horror film written and direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pseudodrephalys</td>\n",
       "      <td>Pseudodrephalys is a genus of South American s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anathallis_linearifolia</td>\n",
       "      <td>Anathallis linearifolia is a species of orchid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Usserød_Å</td>\n",
       "      <td>Usserød Å , the principal drainage of Sjælsø L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swimming_at_the_2015_World_Aquatics_Championsh...</td>\n",
       "      <td>The Women 's 100 metre freestyle competition o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0                              HazMat_-LRB-film-RRB-   \n",
       "1                                    Pseudodrephalys   \n",
       "2                            Anathallis_linearifolia   \n",
       "3                                          Usserød_Å   \n",
       "4  Swimming_at_the_2015_World_Aquatics_Championsh...   \n",
       "\n",
       "                                                text  \n",
       "0  HazMat is a 2013 horror film written and direc...  \n",
       "1  Pseudodrephalys is a genus of South American s...  \n",
       "2  Anathallis linearifolia is a species of orchid...  \n",
       "3  Usserød Å , the principal drainage of Sjælsø L...  \n",
       "4  The Women 's 100 metre freestyle competition o...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "little-completion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nikolaj Coster-Waldau worked with the Fox Broa...</td>\n",
       "      <td>[Waldau_-LRB-surname-RRB-, Waldau, Fox_Broadca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adrienne Bailon is an accountant.</td>\n",
       "      <td>[Accountant, Adrienne_Bailon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful reached number two on the Billboard ...</td>\n",
       "      <td>[Billboard_Hot_100, Number_Two_-LRB-film-RRB-,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neal Schon was named in 1954.</td>\n",
       "      <td>[Neal_Schon, 1954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Boston Celtics play their home games at TD...</td>\n",
       "      <td>[TD_Garden, TD, Boston_Garden, Boston_Celtics]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Nikolaj Coster-Waldau worked with the Fox Broa...   \n",
       "1                  Adrienne Bailon is an accountant.   \n",
       "2  Beautiful reached number two on the Billboard ...   \n",
       "3                      Neal Schon was named in 1954.   \n",
       "4  The Boston Celtics play their home games at TD...   \n",
       "\n",
       "                                                docs  \n",
       "0  [Waldau_-LRB-surname-RRB-, Waldau, Fox_Broadca...  \n",
       "1                      [Accountant, Adrienne_Bailon]  \n",
       "2  [Billboard_Hot_100, Number_Two_-LRB-film-RRB-,...  \n",
       "3                                 [Neal_Schon, 1954]  \n",
       "4     [TD_Garden, TD, Boston_Garden, Boston_Celtics]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "saving-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      100000 non-null  object\n",
      " 1   text    100000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "docs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faced-transportation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   query   50 non-null     object\n",
      " 1   docs    50 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 928.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "queries_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-ocean",
   "metadata": {},
   "source": [
    "## Actividad 1\n",
    "\n",
    "Implementar 2 modelos de RI que utilicen los algoritmos LSA (truncated SVD) y LDA para identificar la distribución de tópicos de los documentos. Los modelos de RI deben usar esta distribución de tópicos para recuperar los documentos relevantes para una consulta dada. Existen varias formas de utilizar el análisis de tópicos en RI. Explicar cuál es la técnica utilizada y cuál es la intención de usar el análisis de tópicos en RI.\n",
    "\n",
    "---\n",
    "\n",
    "- **Técnica utilizada: utilizar una nueva matriz término documento $C_k$ de tal forma que tenga un menor rango que la matriz término documento original $C$ mediante la descomposición por valores singulares SVD**\n",
    "- **La intención del análisis de tópicos es resolver los problemas de polisemia (múltiples significados para una misma palabra) y sinominia (múltiples palabras pueden tener un mismoo significado)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-punch",
   "metadata": {},
   "source": [
    "### Pre procesamiento\n",
    "\n",
    "1. Obtención de documentos \n",
    "2. Limpieza de documentos\n",
    "3. Construcción de matriz término-documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dressed-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finite-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Obtención de documentos\n",
    "docs = docs_df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conceptual-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    HazMat is a 2013 horror film written and direc...\n",
      "1    Pseudodrephalys is a genus of South American s...\n",
      "2    Anathallis linearifolia is a species of orchid...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(docs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interracial-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "structural-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Limpieza de documentos\n",
    "docs = [clean(doc).split() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "painful-clinic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hazmat', '2013', 'horror', 'film', 'written', 'directed', 'lou', 'simon'], ['pseudodrephalys', 'genus', 'south', 'american', 'skipper', 'butterfly', 'family', 'hesperiidae'], ['anathallis', 'linearifolia', 'specie', 'orchid', 'linearifolia']]\n"
     ]
    }
   ],
   "source": [
    "print(docs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minus-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Construcción matriz término documento\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "veterinary-surface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(315882 unique tokens: ['2013', 'directed', 'film', 'hazmat', 'horror']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "equivalent-gasoline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of docs: 100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)],\n",
       " [(16, 1), (17, 2), (18, 1), (19, 1)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Num of docs: {len(corpus)}\")\n",
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-maine",
   "metadata": {},
   "source": [
    "### Modelo de Análisis Semántico Latente (LSA)\n",
    "\n",
    "- La idea general es ocupar una representación $C_k$ de menor rango que la matriz término-documento $C$ utilizando descomposición por valor singular en donde $k\\approx $ a centenas\n",
    "- Generamos un mapeo de cada documento y término a un conjunto de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "helpful-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 180\n",
    "lsi_model = models.LsiModel(corpus, id2word=dictionary)\n",
    "corpus_lsi = lsi_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "latest-answer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.636*\"rrb\" + 0.636*\"lrb\" + 0.281*\"paris\"'),\n",
       " (1, '0.541*\"judaism\" + 0.390*\"press\" + 0.300*\"study\"'),\n",
       " (2, '-0.878*\"paris\" + -0.232*\"de\" + 0.208*\"rrb\"'),\n",
       " (3, '0.862*\"part\" + 0.232*\"s\" + -0.083*\"lrb\"'),\n",
       " (4, '0.537*\"s\" + -0.425*\"part\" + 0.160*\"first\"'),\n",
       " (5, '-0.999*\"amomum\" + -0.005*\"specie\" + -0.005*\"flavorubellum\"'),\n",
       " (6, '-0.646*\"county\" + -0.271*\"ft\" + -0.267*\"el\"'),\n",
       " (7, '-0.657*\"robert\" + -0.476*\"raf\" + -0.365*\"richard\"'),\n",
       " (8, '0.443*\"julien\" + 0.431*\"born\" + 0.320*\"french\"'),\n",
       " (9, '0.378*\"album\" + -0.290*\"school\" + 0.265*\"county\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model.print_topics(num_topics=10, num_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-imperial",
   "metadata": {},
   "source": [
    "### Modelo Latent Dirichlet Allocation (LDA)\n",
    "- Dado un conjunto de datos de doocumentos, la idea es realizar un seguimiento e intentar averiguar los temas que generarían documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "expired-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel(corpus, id2word=dictionary, num_topics=NUM_TOPICS)\n",
    "corpus_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unsigned-reflection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(80, '0.091*\"navy\" + 0.082*\"ship\" + 0.059*\"character\"'),\n",
       " (17, '0.076*\"better\" + 0.055*\"left\" + 0.046*\"deputy\"'),\n",
       " (90, '0.114*\"light\" + 0.067*\"winter\" + 0.042*\"commonwealth\"'),\n",
       " (111, '0.089*\"mark\" + 0.063*\"m\" + 0.051*\"dedicated\"'),\n",
       " (173, '0.092*\"hotel\" + 0.082*\"bill\" + 0.076*\"sun\"'),\n",
       " (28, '0.094*\"competition\" + 0.053*\"metre\" + 0.030*\"competed\"'),\n",
       " (96, '0.144*\"produced\" + 0.117*\"star\" + 0.101*\"production\"'),\n",
       " (41, '0.113*\"point\" + 0.064*\"half\" + 0.052*\"coast\"'),\n",
       " (89, '0.176*\"north\" + 0.158*\"right\" + 0.075*\"carolina\"'),\n",
       " (76, '0.094*\"west\" + 0.057*\"water\" + 0.043*\"bridge\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(num_topics=10, num_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-click",
   "metadata": {},
   "source": [
    "### Persistencia de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "quarterly-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, suffix):\n",
    "    with tempfile.NamedTemporaryFile(prefix='model-', suffix=suffix, delete=False) as tmp:\n",
    "        model.save(tmp.name) \n",
    "    return tmp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "frozen-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/48/3g13bfjj3g56jyfv2g7zr_c00000gp/T/model-zidtfwyt.lsi\n"
     ]
    }
   ],
   "source": [
    "lsi_name = save_model(lsi_model, suffix='.lsi')\n",
    "print(lsi_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "incredible-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/48/3g13bfjj3g56jyfv2g7zr_c00000gp/T/model-m4gu3j94.lda\n"
     ]
    }
   ],
   "source": [
    "lda_name = save_model(lda_model, suffix='.lda')\n",
    "print(lda_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-queens",
   "metadata": {},
   "source": [
    "## Actividad 2\n",
    "\n",
    "Utilizando las consultas del archivo query-sub.jsonl, obtener las curvas recall-precisión para los 2 modelos de RI basados en tópicos. Reportar el mejor valor de F1 obtenido para cada uno. También reportar el MAP resultante.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "protecting-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_from_list_of_tuples(list_of_tuples):\n",
    "    it = map(lambda list_of_tuples: list_of_tuples[0], list_of_tuples)\n",
    "    return set(it)\n",
    "\n",
    "def get_docs_from_topics(topics_of_interest, corpus):\n",
    "    s_topics_of_interest = set_from_list_of_tuples(topics_of_interest)\n",
    "    n = len(s_topics_of_interest)\n",
    "    indices = []\n",
    "    doc_idx = 0\n",
    "    for topics in corpus:\n",
    "        s_topics = set_from_list_of_tuples(topics)\n",
    "        if (len(s_topics_of_interest.intersection(s_topics)) == n):\n",
    "            indices.append(doc_idx)\n",
    "        doc_idx += 1\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "greek-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_lsi_model = models.LsiModel.load(lsi_name)\n",
    "loaded_lda_model = models.LdaModel.load(lda_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "corresponding-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lsi = loaded_lsi_model[corpus]\n",
    "corpus_lda = loaded_lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "miniature-disclosure",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nikolaj Coster-Waldau worked with the Fox Broa...</td>\n",
       "      <td>[Waldau_-LRB-surname-RRB-, Waldau, Fox_Broadca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adrienne Bailon is an accountant.</td>\n",
       "      <td>[Accountant, Adrienne_Bailon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful reached number two on the Billboard ...</td>\n",
       "      <td>[Billboard_Hot_100, Number_Two_-LRB-film-RRB-,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neal Schon was named in 1954.</td>\n",
       "      <td>[Neal_Schon, 1954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Boston Celtics play their home games at TD...</td>\n",
       "      <td>[TD_Garden, TD, Boston_Garden, Boston_Celtics]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Nikolaj Coster-Waldau worked with the Fox Broa...   \n",
       "1                  Adrienne Bailon is an accountant.   \n",
       "2  Beautiful reached number two on the Billboard ...   \n",
       "3                      Neal Schon was named in 1954.   \n",
       "4  The Boston Celtics play their home games at TD...   \n",
       "\n",
       "                                                docs  \n",
       "0  [Waldau_-LRB-surname-RRB-, Waldau, Fox_Broadca...  \n",
       "1                      [Accountant, Adrienne_Bailon]  \n",
       "2  [Billboard_Hot_100, Number_Two_-LRB-film-RRB-,...  \n",
       "3                                 [Neal_Schon, 1954]  \n",
       "4     [TD_Garden, TD, Boston_Garden, Boston_Celtics]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "electrical-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = queries_df['query']\n",
    "queries = [clean(q).split() for q in queries]\n",
    "q_corpus = [dictionary.doc2bow(q) for q in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ordinary-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_precision(queries_corpus, docs_corpus, model_str, docs_df, queries_df):\n",
    "    q_idx = 0\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    f1s = []\n",
    "    for query in queries_corpus:\n",
    "        if model_str == 'lsi':\n",
    "            topics = loaded_lsi_model[query]\n",
    "            topics.sort(key=lambda y: y[1])\n",
    "            topics_of_interest = topics[-4:]\n",
    "        else:\n",
    "            topics_of_interest = loaded_lda_model[query][:4]\n",
    "        docs_indices = get_docs_from_topics(topics_of_interest, docs_corpus)\n",
    "        if (len(docs_indices) == 0):\n",
    "            q_idx += 1\n",
    "            continue\n",
    "        \n",
    "        relevant_docs = queries_df.iloc[q_idx, 1]\n",
    "        retrieved_docs_df = docs_df.iloc[docs_indices]\n",
    "        relevant_retrieved_docs_df = retrieved_docs_df[retrieved_docs_df['id'].isin(relevant_docs)]\n",
    "        \n",
    "        # recall\n",
    "        total_relevant = len(relevant_docs)\n",
    "        relevant_retrieved = relevant_retrieved_docs_df.shape[0]\n",
    "        R = relevant_retrieved / total_relevant\n",
    "        recalls.append(R)\n",
    "        \n",
    "        # precision\n",
    "        total_retrieved = retrieved_docs_df.shape[0]\n",
    "        P = relevant_retrieved / total_retrieved\n",
    "        precisions.append(P)\n",
    "        \n",
    "        # f1 score\n",
    "        try: \n",
    "            f1 = (2*P*R) / (P + R)\n",
    "        except:\n",
    "            f1 = 0\n",
    "        f1s.append(f1)\n",
    "        \n",
    "        q_idx += 1\n",
    "    return pd.DataFrame({\n",
    "        'recall': recalls, 'precision': precisions, 'f1': f1s\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_precision_lda_df = get_recall_precision(q_corpus, corpus_lda, 'lda', docs_df, queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_precision_lsi_df = get_recall_precision(q_corpus, corpus_lda, 'lsi', docs_df, queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_precicion_lda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_precicion_lsi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
